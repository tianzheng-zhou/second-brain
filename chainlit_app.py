import chainlit as cl
import os
import shutil
import tempfile
from pathlib import Path
import sys

# Add project root to sys.path to ensure imports work correctly
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Import custom data layer
from personal_brain.core.chainlit_datalayer import SQLiteDataLayer

# Import existing backend logic
from personal_brain.core.ask import ask_brain
from personal_brain.core.ingestion import ingest_path
from personal_brain.core.database import (
    get_all_files, 
    delete_file_record
)

# Initialize Data Layer
cl_data_layer = SQLiteDataLayer()

@cl.data_layer
def get_data_layer():
    return cl_data_layer

@cl.password_auth_callback
async def auth_callback(username, password):
    # print(f"[DEBUG] auth_callback for user: {username}")
    # Default simple authentication
    if username == "admin" and password == "admin":
        # Ensure user exists in DB and get stable ID
        persisted_user = await cl_data_layer.get_user(username)
        if not persisted_user:
            # Create user if not exists
            temp_user = cl.User(identifier=username)
            persisted_user = await cl_data_layer.create_user(temp_user)
        
        # Return User with STABLE ID from database
        # This ensures threads are linked to the same user across sessions
        user = cl.User(identifier=username)
        if persisted_user and persisted_user.id:
            # print(f"[DEBUG] Assigning persisted ID to user: {persisted_user.id}")
            # Force set the ID to match database
            # Note: cl.User might be a Pydantic model or DataClass, handling both
            if hasattr(user, "id"):
                user.id = persisted_user.id
            else:
                # Fallback if id is not a direct attribute (unlikely in Chainlit)
                object.__setattr__(user, "id", persisted_user.id)
            
            # Update metadata if needed
            if hasattr(user, "metadata"):
                user.metadata = persisted_user.metadata
                
        return user
    # print(f"[DEBUG] Auth failed for user: {username}")
    return None

@cl.on_chat_start
async def start():
    """Initialize the chat session."""
    # user = cl.user_session.get("user")
    # if user:
    #     print(f"[DEBUG] on_chat_start: user={user.identifier}, id={user.id}")
    # else:
    #     print("[DEBUG] on_chat_start: No user in session")

    # Initialize empty history for LLM context
    cl.user_session.set("history", [])
    
    # Display welcome message
    await cl.Message(content="ðŸ‘‹ Welcome to **PersonalBrain**! \n\nUpload files to add them to your knowledge base, or ask questions to search your notes.").send()
    
    # User is already handled in auth_callback, no need to re-check here

@cl.on_chat_resume
async def on_chat_resume(thread: cl.types.ThreadDict):
    """Restore the chat session when a user clicks on a history item."""
    # Rebuild history for LLM context from the thread steps
    history = []
    # print(f"[DEBUG] on_chat_resume thread keys: {thread.keys()}")
    
    # Check if 'steps' is in thread, if not, try to fetch it or use empty
    steps = thread.get("steps", [])
    
    for step in steps:
        # Only include messages in context, not tool outputs or other steps
        if step["type"] == "user_message":
            history.append({"role": "user", "content": step["output"]})
        elif step["type"] == "assistant_message":
            history.append({"role": "assistant", "content": step["output"]})
    
    # Keep only last 10 turns (20 messages) to avoid token limit
    if len(history) > 20:
        history = history[-20:]
        
    cl.user_session.set("history", history)
    # print(f"[DEBUG] Resumed chat with {len(history)} messages in history")

@cl.set_chat_profiles
async def chat_profile():
    return [
        cl.ChatProfile(
            name="RAG Assistant",
            markdown_description="Ask questions about your documents.",
            icon="https://picsum.photos/200",
        )
    ]

@cl.action_callback("delete_file")
async def on_delete_file(action: cl.Action):
    file_id = action.payload.get("value")
    # Delete file logic
    try:
        if delete_file_record(file_id):
            await cl.Message(content=f"âœ… File {file_id} deleted successfully.").send()
            # Refresh list if it was side view? Hard to refresh side view without new message.
        else:
            await cl.Message(content=f"âŒ Failed to delete file {file_id}.").send()
    except Exception as e:
        await cl.Message(content=f"Error deleting file: {e}").send()

async def list_files_message(display_in_side_view=False):
    files = get_all_files()
    if not files:
        content = "No files found in database."
        if display_in_side_view:
             await cl.Message(content=content).send()
        return cl.Message(content=content)
    else:
        file_list_md = "**Your Knowledge Base:**\n\n"
        actions = []
        for f in files: 
            file_list_md += f"- **{f['filename']}** ({f['type']}) - {f.get('size_bytes', 0)//1024} KB\n"
            actions.append(
                cl.Action(name="delete_file", payload={"value": str(f['id'])}, label=f"ðŸ—‘ï¸ Delete {f['filename'][:15]}...")
            )
        
        if display_in_side_view:
             element = cl.Text(name="çŸ¥è¯†åº“åˆ—è¡¨", content=file_list_md, display="side", language="markdown")
             await cl.Message(content="âœ… åˆ—è¡¨å·²ç”Ÿæˆï¼\nè¯·ç‚¹å‡»ä¸‹æ–¹çš„ **â€œçŸ¥è¯†åº“åˆ—è¡¨â€** æŒ‰é’®/å›¾æ ‡ï¼Œåœ¨å³ä¾§ä¾§è¾¹æ æŸ¥çœ‹è¯¦ç»†å†…å®¹ ðŸ‘‰", elements=[element]).send()
             return None
        
        # Limit actions for inline display to avoid clutter
        if len(actions) > 10:
            file_list_md += "\n*(Showing first 10 delete buttons)*"
            actions = actions[:10]
            
        return cl.Message(content=file_list_md, actions=actions)

@cl.on_message
async def main(message: cl.Message):
    """Handle incoming messages (text and files)."""
    
    # --- 1. Handle Commands ---
    if message.content.strip() == "/files":
        msg = await list_files_message(display_in_side_view=False)
        if msg:
            await msg.send()
        return

    if message.content.strip() == "/side":
        await list_files_message(display_in_side_view=True)
        return

    # --- 2. Handle File Uploads ---
    if message.elements:
        processing_msg = cl.Message(content="ðŸ“¥ Processing uploaded files...")
        await processing_msg.send()
        
        count = 0
        # Create a temporary directory to handle uploads safely
        temp_dir = tempfile.mkdtemp()
        
        try:
            for element in message.elements:
                # Check for file path (Chainlit v1+)
                if hasattr(element, "path"):
                    original_name = element.name
                    # Create a path with original filename in temp dir
                    # This is important because ingest_path uses the filename extension to determine file type
                    temp_file_path = os.path.join(temp_dir, original_name)
                    
                    # Copy the temp file to our temp path with correct name
                    shutil.copy2(element.path, temp_file_path)
                    
                    status_msg = cl.Message(content=f"â³ Ingesting {original_name}...")
                    await status_msg.send()
                    
                    try:
                        # Run ingestion in a separate thread to avoid blocking the UI
                        # ingest_path is synchronous, so we use cl.make_async
                        await cl.make_async(ingest_path)(temp_file_path)
                        count += 1
                        status_msg.content = f"âœ… Successfully ingested: {original_name}"
                        await status_msg.update()
                    except Exception as e:
                        status_msg.content = f"âŒ Failed to ingest {original_name}: {str(e)}"
                        await status_msg.update()
            
            if count > 0:
                await cl.Message(content=f"ðŸŽ‰ Processed {count} files successfully.").send()
                
        finally:
            # Cleanup temp directory
            try:
                shutil.rmtree(temp_dir, ignore_errors=True)
            except:
                pass

    # --- 3. Handle Text Query (RAG) ---
    # Only proceed if there is text content
    if message.content:
        
        msg = cl.Message(content="")
        await msg.send()
        
        # Get chat history
        history = cl.user_session.get("history", [])
        
        try:
            # Call your existing RAG function
            # ask_brain returns (response_stream, sources)
            # We need to make sure ask_brain is compatible with async calls if it's blocking
            response_stream, sources = await cl.make_async(ask_brain)(message.content, history=history, stream=True)
            
            full_response = ""
            
            if isinstance(response_stream, str):
                # Error message returned as string
                full_response = f"Error: {response_stream}"
                msg.content = full_response
                await msg.update()
            else:
                # Stream the response from OpenAI client generator
                for chunk in response_stream:
                    if chunk.choices and chunk.choices[0].delta.content:
                        token = chunk.choices[0].delta.content
                        full_response += token
                        await msg.stream_token(token)
                
                # Append sources if available
                if sources:
                    source_text = "\n\n**ðŸ“š References:**\n"
                    for i, src in enumerate(sources, 1):
                        source_text += f"{i}. **{src['filename']}** (Score: {src['score']:.4f})\n"
                    await msg.stream_token(source_text)
                    # Don't save sources text to history context, just the answer
                
                await msg.update()
                
                # Update history (keep last 10 turns)
                history.append({"role": "user", "content": message.content})
                history.append({"role": "assistant", "content": full_response})
                if len(history) > 20:
                    history = history[-20:]
                cl.user_session.set("history", history)
                
        except Exception as e:
            msg.content = f"Error processing query: {str(e)}"
            await msg.update()
